{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from models import resnet18\n",
    "from dataset import PosterDataset, Resize, ToTensor\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "transformed_dataset = PosterDataset(csv_file='./data.txt',\n",
    "                                    root_dir='../posters/',\n",
    "                                    transform=transforms.Compose([\n",
    "                                        Resize(),\n",
    "                                        ToTensor()\n",
    "                                    ]))\n",
    "train_size = int(0.8*len(transformed_dataset)+1)\n",
    "test_size = int(0.2*len(transformed_dataset))\n",
    "train_dataset, test_dataset = random_split(transformed_dataset, [train_size, test_size])\n",
    "data_loader1 = DataLoader(train_dataset, batch_size=8,shuffle=True)\n",
    "data_loader2 = DataLoader(test_dataset, batch_size=8,shuffle=True)\n",
    "print(len(data_loader1))\n",
    "print(len(data_loader2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  [ 0 / 278 ]  loss:  2.974290370941162\n",
      "epoch:  0  [ 1 / 278 ]  loss:  6.352252006530762\n",
      "epoch:  0  [ 2 / 278 ]  loss:  3.431450128555298\n",
      "epoch:  0  [ 3 / 278 ]  loss:  10.02437973022461\n",
      "epoch:  0  [ 4 / 278 ]  loss:  2.7245047092437744\n",
      "epoch:  0  [ 5 / 278 ]  loss:  7.656571388244629\n",
      "epoch:  0  [ 6 / 278 ]  loss:  8.653200149536133\n",
      "epoch:  0  [ 7 / 278 ]  loss:  5.788845062255859\n",
      "epoch:  0  [ 8 / 278 ]  loss:  6.65566873550415\n",
      "epoch:  0  [ 9 / 278 ]  loss:  3.440462112426758\n",
      "epoch:  0  [ 10 / 278 ]  loss:  2.7505438327789307\n",
      "epoch:  0  [ 11 / 278 ]  loss:  3.4973886013031006\n",
      "epoch:  0  [ 12 / 278 ]  loss:  3.2377116680145264\n",
      "epoch:  0  [ 13 / 278 ]  loss:  5.8137969970703125\n",
      "epoch:  0  [ 14 / 278 ]  loss:  3.0313119888305664\n",
      "epoch:  0  [ 15 / 278 ]  loss:  4.761716365814209\n",
      "epoch:  0  [ 16 / 278 ]  loss:  2.778014898300171\n",
      "epoch:  0  [ 17 / 278 ]  loss:  2.913270950317383\n",
      "epoch:  0  [ 18 / 278 ]  loss:  4.094699859619141\n",
      "epoch:  0  [ 19 / 278 ]  loss:  3.3849384784698486\n",
      "epoch:  0  [ 20 / 278 ]  loss:  3.412661075592041\n",
      "epoch:  0  [ 21 / 278 ]  loss:  2.3333487510681152\n",
      "epoch:  0  [ 22 / 278 ]  loss:  2.3493058681488037\n",
      "epoch:  0  [ 23 / 278 ]  loss:  3.566720485687256\n",
      "epoch:  0  [ 24 / 278 ]  loss:  2.6062393188476562\n",
      "epoch:  0  [ 25 / 278 ]  loss:  2.2391245365142822\n",
      "epoch:  0  [ 26 / 278 ]  loss:  2.9278604984283447\n",
      "epoch:  0  [ 27 / 278 ]  loss:  2.6078972816467285\n",
      "epoch:  0  [ 28 / 278 ]  loss:  2.4767463207244873\n",
      "epoch:  0  [ 29 / 278 ]  loss:  2.3275277614593506\n",
      "epoch:  0  [ 30 / 278 ]  loss:  2.9161019325256348\n",
      "epoch:  0  [ 31 / 278 ]  loss:  2.717637538909912\n",
      "epoch:  0  [ 32 / 278 ]  loss:  2.043104887008667\n",
      "epoch:  0  [ 33 / 278 ]  loss:  2.5000436305999756\n",
      "epoch:  0  [ 34 / 278 ]  loss:  3.2358248233795166\n",
      "epoch:  0  [ 35 / 278 ]  loss:  2.712779998779297\n",
      "epoch:  0  [ 36 / 278 ]  loss:  2.2494218349456787\n",
      "epoch:  0  [ 37 / 278 ]  loss:  2.2219245433807373\n",
      "epoch:  0  [ 38 / 278 ]  loss:  2.875455856323242\n",
      "epoch:  0  [ 39 / 278 ]  loss:  2.859464168548584\n",
      "epoch:  0  [ 40 / 278 ]  loss:  2.497492551803589\n",
      "epoch:  0  [ 41 / 278 ]  loss:  2.269798994064331\n",
      "epoch:  0  [ 42 / 278 ]  loss:  2.420870304107666\n",
      "epoch:  0  [ 43 / 278 ]  loss:  2.749223232269287\n",
      "epoch:  0  [ 44 / 278 ]  loss:  2.0206828117370605\n",
      "epoch:  0  [ 45 / 278 ]  loss:  2.8550424575805664\n",
      "epoch:  0  [ 46 / 278 ]  loss:  3.212557315826416\n",
      "epoch:  0  [ 47 / 278 ]  loss:  2.7175092697143555\n",
      "epoch:  0  [ 48 / 278 ]  loss:  3.441812515258789\n",
      "epoch:  0  [ 49 / 278 ]  loss:  2.24224591255188\n",
      "epoch:  0  [ 50 / 278 ]  loss:  1.6681902408599854\n",
      "epoch:  0  [ 51 / 278 ]  loss:  2.4046194553375244\n",
      "epoch:  0  [ 52 / 278 ]  loss:  3.525085926055908\n",
      "epoch:  0  [ 53 / 278 ]  loss:  2.905548095703125\n",
      "epoch:  0  [ 54 / 278 ]  loss:  3.062224864959717\n",
      "epoch:  0  [ 55 / 278 ]  loss:  2.41717267036438\n",
      "epoch:  0  [ 56 / 278 ]  loss:  2.7117204666137695\n",
      "epoch:  0  [ 57 / 278 ]  loss:  1.8940954208374023\n",
      "epoch:  0  [ 58 / 278 ]  loss:  2.1464223861694336\n",
      "epoch:  0  [ 59 / 278 ]  loss:  2.1321020126342773\n",
      "epoch:  0  [ 60 / 278 ]  loss:  2.401149272918701\n",
      "epoch:  0  [ 61 / 278 ]  loss:  2.7797131538391113\n",
      "epoch:  0  [ 62 / 278 ]  loss:  2.9486029148101807\n",
      "epoch:  0  [ 63 / 278 ]  loss:  2.666160821914673\n",
      "epoch:  0  [ 64 / 278 ]  loss:  2.6589467525482178\n",
      "epoch:  0  [ 65 / 278 ]  loss:  2.3680312633514404\n",
      "epoch:  0  [ 66 / 278 ]  loss:  2.362752676010132\n",
      "epoch:  0  [ 67 / 278 ]  loss:  3.9135043621063232\n",
      "epoch:  0  [ 68 / 278 ]  loss:  3.6275243759155273\n",
      "epoch:  0  [ 69 / 278 ]  loss:  2.8944573402404785\n",
      "epoch:  0  [ 70 / 278 ]  loss:  2.376188278198242\n",
      "epoch:  0  [ 71 / 278 ]  loss:  2.526913642883301\n",
      "epoch:  0  [ 72 / 278 ]  loss:  2.921025276184082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\PIL\\TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 11468800 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "D:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\PIL\\TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 37093376 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "D:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\PIL\\TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 19988480 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "D:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\PIL\\TiffImagePlugin.py:709: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 10. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  [ 73 / 278 ]  loss:  2.3338358402252197\n",
      "epoch:  0  [ 74 / 278 ]  loss:  2.488616466522217\n",
      "epoch:  0  [ 75 / 278 ]  loss:  2.4744362831115723\n",
      "epoch:  0  [ 76 / 278 ]  loss:  2.435516357421875\n",
      "epoch:  0  [ 77 / 278 ]  loss:  2.5986361503601074\n",
      "epoch:  0  [ 78 / 278 ]  loss:  2.659709930419922\n",
      "epoch:  0  [ 79 / 278 ]  loss:  2.415632724761963\n",
      "epoch:  0  [ 80 / 278 ]  loss:  2.2891411781311035\n",
      "epoch:  0  [ 81 / 278 ]  loss:  2.170086145401001\n",
      "epoch:  0  [ 82 / 278 ]  loss:  2.598045587539673\n",
      "epoch:  0  [ 83 / 278 ]  loss:  2.837629556655884\n",
      "epoch:  0  [ 84 / 278 ]  loss:  2.3145039081573486\n",
      "epoch:  0  [ 85 / 278 ]  loss:  2.4555115699768066\n",
      "epoch:  0  [ 86 / 278 ]  loss:  2.2946152687072754\n",
      "epoch:  0  [ 87 / 278 ]  loss:  2.0851337909698486\n",
      "epoch:  0  [ 88 / 278 ]  loss:  2.4678030014038086\n",
      "epoch:  0  [ 89 / 278 ]  loss:  2.6255576610565186\n",
      "epoch:  0  [ 90 / 278 ]  loss:  2.5258450508117676\n",
      "epoch:  0  [ 91 / 278 ]  loss:  2.6164238452911377\n",
      "epoch:  0  [ 92 / 278 ]  loss:  2.375278949737549\n",
      "epoch:  0  [ 93 / 278 ]  loss:  2.303490400314331\n",
      "epoch:  0  [ 94 / 278 ]  loss:  2.56571626663208\n",
      "epoch:  0  [ 95 / 278 ]  loss:  1.8339478969573975\n",
      "epoch:  0  [ 96 / 278 ]  loss:  2.909468650817871\n",
      "epoch:  0  [ 97 / 278 ]  loss:  2.532674789428711\n",
      "epoch:  0  [ 98 / 278 ]  loss:  2.7307910919189453\n",
      "epoch:  0  [ 99 / 278 ]  loss:  2.9617209434509277\n",
      "epoch:  0  [ 100 / 278 ]  loss:  2.796353578567505\n",
      "epoch:  0  [ 101 / 278 ]  loss:  2.4583041667938232\n",
      "epoch:  0  [ 102 / 278 ]  loss:  2.1418068408966064\n",
      "epoch:  0  [ 103 / 278 ]  loss:  2.26667857170105\n",
      "epoch:  0  [ 104 / 278 ]  loss:  3.257755994796753\n",
      "epoch:  0  [ 105 / 278 ]  loss:  2.3770227432250977\n",
      "epoch:  0  [ 106 / 278 ]  loss:  3.1949212551116943\n",
      "epoch:  0  [ 107 / 278 ]  loss:  2.5068469047546387\n",
      "epoch:  0  [ 108 / 278 ]  loss:  2.2299695014953613\n",
      "epoch:  0  [ 109 / 278 ]  loss:  2.4316229820251465\n",
      "epoch:  0  [ 110 / 278 ]  loss:  2.4337639808654785\n",
      "epoch:  0  [ 111 / 278 ]  loss:  2.2193188667297363\n",
      "epoch:  0  [ 112 / 278 ]  loss:  2.4081239700317383\n",
      "epoch:  0  [ 113 / 278 ]  loss:  2.1163883209228516\n",
      "epoch:  0  [ 114 / 278 ]  loss:  2.5269272327423096\n",
      "epoch:  0  [ 115 / 278 ]  loss:  3.077385187149048\n",
      "epoch:  0  [ 116 / 278 ]  loss:  2.537069082260132\n",
      "epoch:  0  [ 117 / 278 ]  loss:  2.260953187942505\n",
      "epoch:  0  [ 118 / 278 ]  loss:  2.5580039024353027\n",
      "epoch:  0  [ 119 / 278 ]  loss:  2.502451181411743\n",
      "epoch:  0  [ 120 / 278 ]  loss:  2.7502992153167725\n",
      "epoch:  0  [ 121 / 278 ]  loss:  2.4880003929138184\n",
      "epoch:  0  [ 122 / 278 ]  loss:  2.1119165420532227\n",
      "epoch:  0  [ 123 / 278 ]  loss:  2.6459686756134033\n",
      "epoch:  0  [ 124 / 278 ]  loss:  2.6825497150421143\n",
      "epoch:  0  [ 125 / 278 ]  loss:  3.023589611053467\n",
      "epoch:  0  [ 126 / 278 ]  loss:  2.0272974967956543\n",
      "epoch:  0  [ 127 / 278 ]  loss:  2.370351791381836\n",
      "epoch:  0  [ 128 / 278 ]  loss:  2.28212308883667\n",
      "epoch:  0  [ 129 / 278 ]  loss:  2.2189924716949463\n",
      "epoch:  0  [ 130 / 278 ]  loss:  2.467169761657715\n",
      "epoch:  0  [ 131 / 278 ]  loss:  2.9662275314331055\n",
      "epoch:  0  [ 132 / 278 ]  loss:  2.7775235176086426\n",
      "epoch:  0  [ 133 / 278 ]  loss:  2.3218138217926025\n",
      "epoch:  0  [ 134 / 278 ]  loss:  2.370966672897339\n",
      "epoch:  0  [ 135 / 278 ]  loss:  2.5597891807556152\n",
      "epoch:  0  [ 136 / 278 ]  loss:  2.3417351245880127\n",
      "epoch:  0  [ 137 / 278 ]  loss:  2.5756142139434814\n",
      "epoch:  0  [ 138 / 278 ]  loss:  2.4341015815734863\n",
      "epoch:  0  [ 139 / 278 ]  loss:  2.516085624694824\n",
      "epoch:  0  [ 140 / 278 ]  loss:  2.323197603225708\n",
      "epoch:  0  [ 141 / 278 ]  loss:  2.8154118061065674\n",
      "epoch:  0  [ 142 / 278 ]  loss:  2.5756640434265137\n",
      "epoch:  0  [ 143 / 278 ]  loss:  2.514084815979004\n",
      "epoch:  0  [ 144 / 278 ]  loss:  2.4117918014526367\n",
      "epoch:  0  [ 145 / 278 ]  loss:  2.267923593521118\n",
      "epoch:  0  [ 146 / 278 ]  loss:  1.9437711238861084\n",
      "epoch:  0  [ 147 / 278 ]  loss:  2.675199031829834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\PIL\\TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 4718592 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  [ 148 / 278 ]  loss:  2.24196195602417\n",
      "epoch:  0  [ 149 / 278 ]  loss:  2.283681869506836\n",
      "epoch:  0  [ 150 / 278 ]  loss:  2.483147144317627\n",
      "epoch:  0  [ 151 / 278 ]  loss:  2.5437941551208496\n",
      "epoch:  0  [ 152 / 278 ]  loss:  2.599973440170288\n",
      "epoch:  0  [ 153 / 278 ]  loss:  2.669032335281372\n",
      "epoch:  0  [ 154 / 278 ]  loss:  2.9106225967407227\n",
      "epoch:  0  [ 155 / 278 ]  loss:  3.263371229171753\n",
      "epoch:  0  [ 156 / 278 ]  loss:  2.2998735904693604\n",
      "epoch:  0  [ 157 / 278 ]  loss:  1.9890421628952026\n",
      "epoch:  0  [ 158 / 278 ]  loss:  2.65230393409729\n",
      "epoch:  0  [ 159 / 278 ]  loss:  2.758401870727539\n",
      "epoch:  0  [ 160 / 278 ]  loss:  2.439993381500244\n",
      "epoch:  0  [ 161 / 278 ]  loss:  2.1920032501220703\n",
      "epoch:  0  [ 162 / 278 ]  loss:  2.34610915184021\n",
      "epoch:  0  [ 163 / 278 ]  loss:  2.3474650382995605\n",
      "epoch:  0  [ 164 / 278 ]  loss:  2.2968344688415527\n",
      "epoch:  0  [ 165 / 278 ]  loss:  1.8239208459854126\n",
      "epoch:  0  [ 166 / 278 ]  loss:  2.1174328327178955\n",
      "epoch:  0  [ 167 / 278 ]  loss:  3.2827210426330566\n",
      "epoch:  0  [ 168 / 278 ]  loss:  2.845919370651245\n",
      "epoch:  0  [ 169 / 278 ]  loss:  2.162707805633545\n",
      "epoch:  0  [ 170 / 278 ]  loss:  2.9036917686462402\n",
      "epoch:  0  [ 171 / 278 ]  loss:  2.12741756439209\n",
      "epoch:  0  [ 172 / 278 ]  loss:  2.704418182373047\n",
      "epoch:  0  [ 173 / 278 ]  loss:  2.6456809043884277\n",
      "epoch:  0  [ 174 / 278 ]  loss:  2.9685215950012207\n",
      "epoch:  0  [ 175 / 278 ]  loss:  2.2851662635803223\n",
      "epoch:  0  [ 176 / 278 ]  loss:  2.5855326652526855\n",
      "epoch:  0  [ 177 / 278 ]  loss:  2.911191463470459\n",
      "epoch:  0  [ 178 / 278 ]  loss:  2.9223127365112305\n",
      "epoch:  0  [ 179 / 278 ]  loss:  2.3588385581970215\n",
      "epoch:  0  [ 180 / 278 ]  loss:  2.341082811355591\n",
      "epoch:  0  [ 181 / 278 ]  loss:  2.8797836303710938\n",
      "epoch:  0  [ 182 / 278 ]  loss:  2.7022714614868164\n",
      "epoch:  0  [ 183 / 278 ]  loss:  2.2516870498657227\n",
      "epoch:  0  [ 184 / 278 ]  loss:  2.5096499919891357\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-6ccd3bd6d80a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m#         print(idx)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#         print(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python\\torch\\ml-100k\\MovRec\\Pic\\train\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python\\torch\\ml-100k\\MovRec\\Pic\\train\\dataset.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, sample)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mnew_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m320\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'label'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'title'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\skimage\\transform\\_warps.py\u001b[0m in \u001b[0;36mresize\u001b[1;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         image = ndi.gaussian_filter(image, anti_aliasing_sigma,\n\u001b[1;32m--> 149\u001b[1;33m                                     cval=cval, mode=ndi_mode)\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;31m# 2-dimensional interpolation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\scipy\\ndimage\\filters.py\u001b[0m in \u001b[0;36mgaussian_filter\u001b[1;34m(input, sigma, order, output, mode, cval, truncate)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m             gaussian_filter1d(input, sigma, axis, order, output,\n\u001b[1;32m--> 289\u001b[1;33m                               mode, cval, truncate)\n\u001b[0m\u001b[0;32m    290\u001b[0m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\scipy\\ndimage\\filters.py\u001b[0m in \u001b[0;36mgaussian_filter1d\u001b[1;34m(input, sigma, axis, order, output, mode, cval, truncate)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;31m# Since we are calling correlate, not convolve, revert the kernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_gaussian_kernel1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcorrelate1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\tensorflow-gpu\\lib\\site-packages\\scipy\\ndimage\\filters.py\u001b[0m in \u001b[0;36mcorrelate1d\u001b[1;34m(input, weights, axis, output, mode, cval, origin)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_mode_to_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     _nd_image.correlate1d(input, weights, axis, output, mode, cval,\n\u001b[1;32m---> 95\u001b[1;33m                           origin)\n\u001b[0m\u001b[0;32m     96\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "model = resnet18().to(device)\n",
    "criteon = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "\n",
    "for epoch in range(1):\n",
    "    model.train()\n",
    "    for idx, item in enumerate(data_loader1):\n",
    "#         print(idx)\n",
    "#         print(x)\n",
    "#         print(label)\n",
    "#         print(title)\n",
    "        x, label = item['image'].to(device), item['label'].to(device)\n",
    "        logits = model(x)\n",
    "        loss = criteon(logits, label)\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        # backporp\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('epoch: ', epoch, ' [', idx, '/', len(data_loader1), '] ', 'loss: ', loss.item())\n",
    "\n",
    "    print('epoch: ', epoch, 'loss: ', loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # test\n",
    "        total_correct = 0\n",
    "        total_num = 0\n",
    "        for idx, (x, label, title) in data_loader2:\n",
    "            x, label = x.to(device), label.to(device)\n",
    "            logits = model(x)\n",
    "            pred = logits.argmax(dim=1)\n",
    "            total_correct += torch.eq(pred, label).float().sum().item()\n",
    "            total_num += x.size(0)\n",
    "\n",
    "        acc = total_correct / total_num\n",
    "        train_acc.append(acc)\n",
    "        print('acc: ', acc, '\\n')\n",
    "\n",
    "    # 保存神经网络\n",
    "    if epoch % 100 == 0:\n",
    "        torch.save(model, 'net.pkl')                      # 保存整个神经网络的结构和模型参数\n",
    "        print('saved in net.pkl')\n",
    "\n",
    "plot_curve(train_loss, 'loss')\n",
    "plot_curve(train_acc, 'acc')\n",
    "\n",
    "# 保存神经网络\n",
    "torch.save(model, 'net.pkl')                      # 保存整个神经网络的结构和模型参数\n",
    "#     torch.save(net.state_dict(), 'net_params.pkl')  # 只保存神经网络的模型参数\n",
    "print('saved in net.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
